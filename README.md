es-kluster

es-1___________________________________________ssh hunter@172.16.80.10
es-2___________________________________________ssh hunter@172.16.80.11
es-3___________________________________________ssh hunter@172.16.80.12
kibana_________________________________________ssh hunter@172.16.80.13


ğŸ“¦ es-kluster

Production-like Elasticsearch 8.19.11 â€“ 3 Node Cluster + Kibana + NFS Snapshots (SLM)

ğŸ— Architecture Overview
Topology
Host	Role	IP	Ports
es-1	master / data / ingest	172.16.80.10	9200, 9300
es-2	master / data / ingest	172.16.80.11	9200, 9300
es-3	master / data / ingest	172.16.80.12	9200, 9300
kibana	Kibana UI	172.16.80.13	5601

Cluster Name: es-kluster
Security: Enabled (TLS + Basic Auth)
Snapshot: NFS shared repository
Backup automation: SLM (Snapshot Lifecycle Management)

ğŸ” Security Model

xpack.security.enabled = true

HTTP TLS enabled

Transport TLS enabled (mutual authentication)

Certificates auto-generated by Elastic security auto-config

Passwords and certs are NOT stored in Git

Cert locations (per node):

/etc/elasticsearch/certs/http.p12
/etc/elasticsearch/certs/transport.p12
ğŸ“‚ Repository Structure
.
â”œâ”€â”€ es-1/
â”‚   â””â”€â”€ elasticsearch.yml
â”œâ”€â”€ es-2/
â”‚   â””â”€â”€ elasticsearch.yml
â”œâ”€â”€ es-3/
â”‚   â””â”€â”€ elasticsearch.yml
â”œâ”€â”€ kibana/
â”‚   â””â”€â”€ kibana.yml
â”œâ”€â”€ INSTALL-STAGES.txt
â””â”€â”€ README.md
ğŸš€ Cluster Validation
Check cluster nodes
PASS='YOUR_ELASTIC_PASSWORD'

curl -k -u "elastic:$PASS" \
https://172.16.80.10:9200/_cat/nodes?v

Expected: 3 nodes listed

Cluster health
curl -k -u "elastic:$PASS" \
https://172.16.80.10:9200/_cluster/health?pretty

Expected:

"status": "green"
"number_of_nodes": 3
Master node
curl -k -u "elastic:$PASS" \
https://172.16.80.10:9200/_cat/master?v
ğŸ’¾ Snapshot Architecture
Storage

NFS shared storage:

/srv/es-snapshots
Mounted as:
/snapshots

Configured in elasticsearch.yml:

path.repo: ["/snapshots"]
Repository

Repository name:

local_repo

Check repository:

curl -k -u "elastic:$PASS" \
https://172.16.80.10:9200/_cat/repositories?v
ğŸ” SLM (Automated Backups)

Policy name:

daily-nfs

Schedule:

02:30 UTC daily

Retention:

keep minimum 7

delete after 7 days

max 30 snapshots

Check SLM policy
curl -k -u "elastic:$PASS" \
https://172.16.80.10:9200/_slm/policy/daily-nfs?human&pretty
Force manual snapshot
curl -k -u "elastic:$PASS" -X POST \
https://172.16.80.10:9200/_slm/policy/daily-nfs/_execute
List snapshots
curl -k -u "elastic:$PASS" \
"https://172.16.80.10:9200/_cat/snapshots/local_repo?v&s=start_time:desc"
â™» Restore Procedure (CRITICAL SECTION)
Restore full cluster snapshot
curl -k -u "elastic:$PASS" -X POST \
"https://172.16.80.10:9200/_snapshot/local_repo/SNAPSHOT_NAME/_restore" \
-H "Content-Type: application/json" \
-d '{
  "indices": "*",
  "ignore_unavailable": true,
  "include_global_state": true
}'
Restore specific index only
curl -k -u "elastic:$PASS" -X POST \
"https://172.16.80.10:9200/_snapshot/local_repo/SNAPSHOT_NAME/_restore" \
-H "Content-Type: application/json" \
-d '{
  "indices": "index_name"
}'
ğŸ” Troubleshooting Quick Reference
401 Authentication error

Wrong elastic password

Using HTTP instead of HTTPS

503 Cluster state not recovered

Master election issue

Seed hosts misconfigured

Transport port blocked

Repository verify fails

/snapshots not shared between nodes

NFS permission issue

path.repo missing

ğŸ›¡ Hardening Recommendations

Firewall restrict 9300 to cluster nodes only

Restrict 9200 to admin/Kibana only

Place Kibana behind reverse proxy

Disable enrollment after cluster stable

Remove cluster.initial_master_nodes after bootstrap

ğŸ‘¨â€ğŸ’» Maintainer

Shodlik Parmonov
DevOps / DevSecOps Engineer
GitHub: https://github.com/shodlik105

ğŸ¯ Status

âœ” 3 Node cluster operational
âœ” Green cluster state
âœ” TLS enabled
âœ” Snapshot repo verified
âœ” SLM automated backups running

